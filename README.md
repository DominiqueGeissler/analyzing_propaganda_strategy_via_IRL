# analyzing_propaganda_strategy_via_IRL

This is the code for the paper "Analyzing the Strategy of Propaganda using Inverse Reinforcement Learning: Evidence from the 2022 Russian Invasion of Ukraine".

## Abstract
The 2022 Russian invasion of Ukraine was accompanied by a large-scale, pro-Russian propaganda campaign on social media. However, the strategy behind the dissemination of propaganda by bots and humans has remained unclear. Here, we analyze the dissemination strategy of bots and humans on Twitter using an inverse reinforcement learning (IRL) approach. Specifically, IRL allows us to model online behaviour as a Markov decision process, where the goal is to infer the underlying reward structure that guides bots and humans. Thereby, we aim to understand empirically whether and how between-user interactions are strategically used to promote the proliferation of Russian propaganda. For this, we leverage a large-scale dataset with 349,455 posts with pro-Russian propaganda from 132,131 users. We show that bots and humans are characterized by different incentives: bots are much more likely to retweet than humans, while humans are more likely to post after others reshared their content. To profile propaganda spreaders, we further use machine learning to test whether the different interaction dynamics set bots vs. humans aside. To the best of our knowledge, this is the first study to leverage IRL to analyze the strategy that drives propaganda dissemination by bots and humans on social media. 
